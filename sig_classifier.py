# -*- coding: utf-8 -*-
"""sig_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d4Blx2TGedBxL3Nq3uIubVXgLeV8xtYV

# Business Decision Signature Detection Use Case

Notebook to create a VGG 16 model to classify between image with **no signature** and with **signature**
"""

# import the required libraries
import os
import random
import numpy as np 
import pandas as pd
import scipy as sp
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tensorflow.keras import layers
from tensorflow.keras.optimizers import *
from tensorflow.keras.callbacks import *
from tensorflow.keras.callbacks import History
from tensorflow.keras.applications import vgg16
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.preprocessing.image import array_to_img, ImageDataGenerator

import cv2

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

"""### Defining folders containing data sets

"""

training_folder = '/content/drive/My Drive/model_data/train'
validation_folder = '/content/drive/My Drive/model_data/val'

test_folder = '/content/drive/My Drive/model_data/test'

# Defining some common parameters
SHAPE = (224,224, 3) # to ensure the shape of all images is same
batch_size = 256 # to define a uniform batch size

"""### Required Functions : model & image labeling

"""

def vgg_model():
    """
    Function to create a modified version of VGG 16 model
    """
    # defining the model to use
    vgg = vgg16.VGG16(weights='imagenet', 
                      include_top=False, 
                      input_shape = SHAPE)
    
    for layer in vgg.layers:
        layer.trainable = False
    
    # adding pooling and dense layers
    x = vgg.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(2, activation="softmax")(x)

    # create and compile the model
    model = Model(vgg.input, x)
    model.compile(optimizer = SGD(learning_rate=0.0001, momentum=0.9),
                  loss = "categorical_crossentropy", 
                  metrics=["accuracy"])
    
    return model

def predict_label(image):
  """
  Function to return a label 0 or 1, given and image to classify.
  """
  
  img = load_img(
      image, target_size=(SHAPE[0, SHAPE[1])
                )

  img_array = img_to_array(img)
  img_array = np.expand_dims(img_array, 0) # Create a batch

  # get the weights for each class
  predictions = model.predict(img_array)
  
  # get the confidence score for the prediction
  score = tf.nn.softmax(predictions[0])

  # get the label for the predicted clas : 0/1
  # depending on which class has the higher score
  label = np.argmax(score)

  # generating class name for the label
  if label == 1 :   cls = 'signature'
  else :   cls = 'no_signature'
  
  return label

"""Rescaling the train, validation and test data

"""

train_gen = ImageDataGenerator(rescale=1/255)

val_gen = ImageDataGenerator(rescale=1/255)

test_gen = ImageDataGenerator(rescale=1/255)

"""### Creating FLOW GENERATORS to train and test the model"""

# indentifying number of classes for test and validation sets
train_generator = train_gen.flow_from_directory(
            directory = training_folder,
            target_size = (SHAPE[0], SHAPE[1]),
            batch_size = batch_size,
            class_mode = 'categorical',
            shuffle = True,
            subset = 'training',
            seed = 33
)

# validation set 
validation_generator = val_gen.flow_from_directory(
            directory = validation_folder,
            target_size = (SHAPE[0], SHAPE[1]),
            batch_size = batch_size,
            class_mode = 'categorical',
            shuffle = True,
            
            seed = 33
)

# testing set

test_generator = test_gen.flow_from_directory(
            '/content/drive/My Drive/model_data', classes=['test'],
            target_size = (SHAPE[0], SHAPE[1]),
            batch_size = 1,
            class_mode = None,
            shuffle = False,
            seed = 33
)

"""Getting the names for the classes"""

class_names = train_generator.class_indices
print(class_names)

labels = train_generator.class_indices
labels = dict((v,k) for k,v in labels.items())

"""### Training the VGG16 model"""

# calling the model
model = vgg_model()

# fitting the model 
history = model.fit(train_generator, 
                    validation_data = validation_generator, 
                    epochs = 25,
                    steps_per_epoch = train_generator.samples//train_generator.batch_size)

# model details
model.summary()

"""### Model Evaluation

Visualizing the loss and accuracy relations
"""

# plotting the curves for training vs. validation accuracy and loss

epochs = 25

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# getting the validation scores
val_score = model.evaluate(validation_generator)
print('Val Loss:', val_score[0])
print('Val accuracy:', val_score[1])

"""### Model Evaluation continued

Retrieving Validation labels from the generator
"""

val_num = validation_generator.samples

label_val = []
for i in range((val_num // validation_generator.batch_size)+1):
    X,y = validation_generator.next()
    label_val.append(y)
        
label_val = np.argmax(np.vstack(label_val), axis=1)

label_val.shape

# making predictions for validation set
predict_val = np.argmax(model.predict(validation_generator),axis=1)

"""Performance checking on Validation Data"""

# Classification Report
print("Classification report")
target_names = ['No_signature', 'Signature']
print(classification_report(label_val, predict_val, target_names = target_names))

# Confusion Matrix
print("Confusion Matrix")
print(confusion_matrix(label_val, predict_val))

"""### Generating predictions for Test dataset"""

# getiing predictions using the model
STEP_SIZE_TEST = test_generator.samples//test_generator.batch_size

# reset before every predict run
test_generator.reset()
pred = model.predict(test_generator,
              steps = STEP_SIZE_TEST,
              verbose=1)

# getting the array for labels of predicted classes
predicted_class_indices = np.argmax(pred,axis=1)

# getting the labels for names of predicted classes
predictions = [labels[k] for k in predicted_class_indices]

"""Storing the results in list using indiviual file prediction

"""

Id_list = []
Expected_list = []
count = 0

for root, direc, files in os.walk(test_folder):
        for f in files:
            # getting each image from the test folder
            img_path = os.path.join(test_folder,f)

            # adding filename to list
            Id_list.append(f[:-4])

            # calling predict_label(image_path) function to get the label
            # adding label to corresponding list
            Expected_list.append(predict_label(img_path))
            count += 1

"""Creating a csv file to save the labels

"""

# populating in a dataframe
labels_df = pd.DataFrame(list(zip(Id_list,Expected_list)),
                            columns = ['Id','Expected']
                            )
# saving results to a csv file label.csv
labels_df.to_csv(r'/content/drive/MyDrive/labels1.csv', index = False)

"""### Saving the model"""

model.save(r'/content/drive/MyDrive/sig_classifier.h5')

"""#### End of notebook"""